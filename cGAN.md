README for Conditional GAN (cGAN) Implementation on Yelp Dataset
________________________________________
Overview: 

This repository contains the implementation of a Conditional Generative Adversarial Network (cGAN) for generating images from the Yelp dataset. The cGAN is trained to generate realistic images based on given labels (food, drink, inside, and outside). The project includes data preprocessing, model training, evaluation, and sample generation.
________________________________________
Getting Started: 

Prerequisites
●	Python >= 3.8
●	PyTorch >= 1.12.0
●	torchvision >= 0.13.0
●	PIL (Pillow) for image handling
●	tqdm for progress tracking
●	numpy for numerical operations
Install dependencies using:
bash
Copy code
pip install -r requirements.txt

________________________________________
Dataset: 

The dataset consists of Yelp images stored in photos/ and metadata in photos.json. Each image is labeled with one of four categories: food, drink, inside, or outside.
Preprocessing: 

●	Invalid or corrupted images are filtered during dataset initialization.
●	Images are resized to 64×6464 \times 6464×64 and normalized to [−1,1][-1, 1][−1,1].
________________________________________
Model Architecture:

Generator:

●	Input: Latent noise vector (zzz) and label embeddings
●	Architecture: 
○	Fully connected layer to reshape latent vector
○	Two upsampling layers with convolution, BatchNorm, and LeakyReLU
○	Final 3×33 \times 33×3 convolution with Tanh activation to produce RGB images
●	Output: 64×64×364 \times 64 \times 364×64×3 RGB image
Discriminator: 

●	Input: Image (64×64×364 \times 64 \times 364×64×3) and label embeddings
●	Architecture:
○	Three convolutional layers with BatchNorm and LeakyReLU
○	Fully connected layer concatenating image and label embeddings
○	Sigmoid activation for final binary classification
●	Output: Real or Fake classification score
________________________________________
Training
Hyperparameters:

●	Latent Dimension: 100
●	Batch Size: 64
●	Learning Rate: 0.0002
●	Betas: (0.5, 0.999) for Adam optimizers
●	Epochs: 10
Steps:

1.	Train Generator:
○	Generate images conditioned on labels.
○	Minimize adversarial loss to fool the Discriminator.
2.	Train Discriminator:
○	Classify real and generated images.
○	Minimize adversarial loss for real (label: 1) and fake images (label: 0).
________________________________________
Evaluation
Metrics:

1.	Inception Score (IS): 
○	Measures image quality and diversity.
○	Score: 2.53 ± 0.12
2.	Frechet Inception Distance (FID): 
○	Measures similarity between real and generated images.
○	Current Issue: FID score returns NaN due to covariance matrix instability.
________________________________________
Results: 

Generated Samples
Sample images generated by the cGAN, conditioned on labels:
●	Food:
●	Drink:
●	Inside:
●	Outside:

LINK: https://github.com/Navneet024/DL-CS2/tree/73ddac006a73143379cc200f7bc123ee3d7f04bf/generated_images 

Insights:

●	The Generator produces visually distinct images for each label.
●	Improvements needed for sharpness and diversity, as highlighted by FID issues.
________________________________________
Future Improvements:

1.	Optimize FID Calculation: 
○	Address covariance computation errors.
○	Use larger samples for better statistics.
2.	Model Tuning: 
○	Experiment with advanced architectures (e.g., deeper convolutional layers).
○	Adjust learning rate schedules for improved convergence.
3.	Augment Dataset: 
○	Include more labeled images for better generalization.

________________________________________
References: 

●	Original Paper: Conditional Generative Adversarial Networks (cGANs)
●	Dataset: Yelp Open Dataset 


